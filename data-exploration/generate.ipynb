{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation & Summaries\n",
    "\n",
    "Use this Jupyter Notebook to take our initial dataset(s) and generate aggregate/reformatted/summarized CSVs usable by our frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and initial variables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "json_out_dir = \"../website/src/lib/data/\"\n",
    "dataset_name = \"census_tracts_processed.csv\"\n",
    "dataset_df = pd.read_csv(dataset_name, dtype={\"geoid\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create aggregate info for each county\n",
    "# GEOID consists of 11 digits, first 2 are state and next 3 are county\n",
    "# matches county ID in map\n",
    "df = dataset_df.copy()\n",
    "df[\"id\"] = df[\"geoid\"].astype(str).str[:5].astype(int)\n",
    "\n",
    "# calculate aggregates\n",
    "def mean_pos(x):\n",
    "    pos_vals = x[x > 0]\n",
    "    return np.round(np.mean(pos_vals), 2)\n",
    "\n",
    "def listify(x):\n",
    "    return list(set(x))\n",
    "    \n",
    "agg = {\n",
    "    \"median_income\": mean_pos,\n",
    "    \"median_home_value\": mean_pos,\n",
    "    \"name\": listify,\n",
    "    \"city\": lambda x: listify(x)[0],\n",
    "    \"metro_area\": lambda x: listify(x)[0],\n",
    "}\n",
    "agg_non_default = agg.keys()\n",
    "agg.update({\n",
    "    col: \"sum\" for col in df.columns if col not in [*agg_non_default, \"id\", \"geoid\"]\n",
    "})\n",
    "agg_df = df.groupby(\"id\").agg(agg).reset_index()\n",
    "\n",
    "# clusters\n",
    "metro_areas = {item: index for index, item in enumerate(agg_df[\"metro_area\"].unique())}\n",
    "agg_df[\"area_cluster\"] = agg_df[\"metro_area\"]\n",
    "agg_df[\"area_cluster\"] = agg_df[\"area_cluster\"].map(metro_areas)\n",
    "\n",
    "# for tracts in agg_df[\"name\"]:\n",
    "#     county = None\n",
    "#     state = None\n",
    "#     for tract in tracts:\n",
    "#         s = tract.split(\", \")\n",
    "#         if county is None:\n",
    "#             county = s[1]\n",
    "#             state = s[2]\n",
    "#         else:\n",
    "#             assert county == s[1] and state == s[2], \"diff county detected! \" + county + state\n",
    "\n",
    "# extract data from name (county/state is clean, ie only one exists per name)\n",
    "agg_df[\"name\"] = agg_df[\"name\"].str[0]\n",
    "agg_df[\"tract_count\"] = len(agg_df[\"name\"])\n",
    "agg_df[[\"name\", \"county\", \"state\"]] = agg_df[\"name\"].str.split(\", \", expand=True)\n",
    "agg_df = agg_df.drop(columns=[\"name\"])\n",
    "\n",
    "# recalculate proportion 25 under\n",
    "agg_df[\"proportion_25_under\"] = agg_df[\"total_population_25_under\"] / agg_df[\"total_population\"]\n",
    "\n",
    "# reorder columns\n",
    "agg_df.insert(5, \"tract_count\", agg_df.pop(\"tract_count\"))\n",
    "agg_df.insert(5, \"state\", agg_df.pop(\"state\"))\n",
    "agg_df.insert(3, \"county\", agg_df.pop(\"county\"))\n",
    "agg_df.insert(6, \"area_cluster\", agg_df.pop(\"area_cluster\"))\n",
    "\n",
    "# convert whole number fields to ints\n",
    "int_cols = [\"total_population\",\n",
    "       \"total_population_25_over\", \"educational_attainment\", \"white_alone\",\n",
    "       \"black_alone\", \"native_alone\", \"asian_alone\",\n",
    "       \"native_hawaiian_pacific_islander\", \"some_other_race_alone\",\n",
    "       \"two_or_more\", \"hispanic_or_latino\", \"total_population_25_under\"]\n",
    "agg_df[int_cols] = agg_df[int_cols].astype(int)\n",
    "\n",
    "# save df\n",
    "agg_df.to_csv(\"county_aggregated.csv\", index=False)\n",
    "\n",
    "# get json\n",
    "agg_df.to_json(json_out_dir + \"county_aggregated.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   observation_date   ASPUS\n",
      "0        2000-01-01  202900\n",
      "1        2000-04-01  202400\n",
      "2        2000-07-01  204100\n",
      "3        2000-10-01  212100\n",
      "4        2001-01-01  211000\n",
      "..              ...     ...\n",
      "95       2023-10-01  498300\n",
      "96       2024-01-01  519700\n",
      "97       2024-04-01  502200\n",
      "98       2024-07-01  498700\n",
      "99       2024-10-01  510300\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "307400\n"
     ]
    }
   ],
   "source": [
    "# avg national housing cost increase\n",
    "# see https://fred.stlouisfed.org/series/ASPUS\n",
    "\n",
    "adj_df = pd.read_csv(\"county_aggregated.csv\")\n",
    "prices = pd.read_csv(\"avg_housing_increase_2000_2024_oct.csv\")\n",
    "\n",
    "print(prices)\n",
    "avg_increase = int(prices.iloc[len(prices) - 1][\"ASPUS\"]) - int(prices.iloc[0][\"ASPUS\"])\n",
    "print(avg_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('family', 5), ('help', 3), ('think', 3), ('means', 3), ('had', 3), ('could', 3), ('were', 3), ('from', 3), ('base', 3), ('each', 3), ('or', 3), ('was', 3), ('one', 3), ('by', 3), ('Donate', 3), ('she', 2), ('mother', 2), ('mean', 2), ('mom', 2), ('way', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Home frequently associated words\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "ignore = [\"\", \"a\", \"and\", \"to\", \"the\", \"is\", \"Habitat\", \"for\", \"in\", \"\\n\\n—\", \"home\", \"place\", \"of\", \"we\", \"our\", \"as\", \"with\", \"her\", \"how\", \"where\", \"A\", \"new\", \"Humanity\", \"on\", \"their\", \"you\", \"that\", \"are\", \"live\", \"Home\", \"can\", \"“Home\", \"I\", \"my\", \"does\", \"—\", \"build\", \"will\", \"share\", \"they\"]\n",
    "\n",
    "with open(\"habitat-page-stripped.txt\", \"r\") as file:\n",
    "    file_content = file.read()\n",
    "counts = Counter([word for word in file_content.split(\" \") if word not in ignore])\n",
    "print(counts.most_common(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
